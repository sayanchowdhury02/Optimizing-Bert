{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X6dWPHUw17-5",
        "outputId": "ece1dae0-861a-4711-d530-37c70df1684f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.40.0)\n",
            "Collecting datasets\n",
            "  Downloading datasets-2.19.0-py3-none-any.whl (542 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m542.0/542.0 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tokenizers in /usr/local/lib/python3.10/dist-packages (0.19.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.2)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.0.3)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<=2024.3.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.5)\n",
            "Collecting huggingface-hub<1.0,>=0.19.3 (from transformers)\n",
            "  Downloading huggingface_hub-0.22.2-py3-none-any.whl (388 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m388.9/388.9 kB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Installing collected packages: xxhash, dill, multiprocess, huggingface-hub, datasets\n",
            "  Attempting uninstall: huggingface-hub\n",
            "    Found existing installation: huggingface-hub 0.20.3\n",
            "    Uninstalling huggingface-hub-0.20.3:\n",
            "      Successfully uninstalled huggingface-hub-0.20.3\n",
            "Successfully installed datasets-2.19.0 dill-0.3.8 huggingface-hub-0.22.2 multiprocess-0.70.16 xxhash-3.4.1\n",
            "--2024-04-26 04:51:04--  http://www.cs.cornell.edu/~cristian/data/cornell_movie_dialogs_corpus.zip\n",
            "Resolving www.cs.cornell.edu (www.cs.cornell.edu)... 132.236.207.36\n",
            "Connecting to www.cs.cornell.edu (www.cs.cornell.edu)|132.236.207.36|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 9916637 (9.5M) [application/zip]\n",
            "Saving to: ‘cornell_movie_dialogs_corpus.zip’\n",
            "\n",
            "cornell_movie_dialo 100%[===================>]   9.46M  23.7MB/s    in 0.4s    \n",
            "\n",
            "2024-04-26 04:51:04 (23.7 MB/s) - ‘cornell_movie_dialogs_corpus.zip’ saved [9916637/9916637]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers datasets tokenizers\n",
        "!wget http://www.cs.cornell.edu/~cristian/data/cornell_movie_dialogs_corpus.zip\n",
        "!unzip -qq cornell_movie_dialogs_corpus.zip\n",
        "!rm cornell_movie_dialogs_corpus.zip\n",
        "!mkdir datasets\n",
        "!mv cornell\\ movie-dialogs\\ corpus/movie_conversations.txt ./datasets\n",
        "!mv cornell\\ movie-dialogs\\ corpus/movie_lines.txt ./datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pVM1NtT01D3u"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "import torch\n",
        "import re\n",
        "import random\n",
        "import transformers, datasets\n",
        "from tokenizers import BertWordPieceTokenizer\n",
        "from transformers import BertTokenizer\n",
        "import tqdm\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import itertools\n",
        "import math\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "from torch.optim import Adam\n",
        "\n",
        "MAX_LEN = 64\n",
        "\n",
        "### loading all data into memory\n",
        "corpus_movie_conv = './datasets/movie_conversations.txt'\n",
        "corpus_movie_lines = './datasets/movie_lines.txt'\n",
        "with open(corpus_movie_conv, 'r', encoding='iso-8859-1') as c:\n",
        "    conv = c.readlines()\n",
        "with open(corpus_movie_lines, 'r', encoding='iso-8859-1') as l:\n",
        "    lines = l.readlines()\n",
        "\n",
        "### splitting text using special lines\n",
        "lines_dic = {}\n",
        "for line in lines:\n",
        "    objects = line.split(\" +++$+++ \")\n",
        "    lines_dic[objects[0]] = objects[-1]\n",
        "\n",
        "### generate question answer pairs\n",
        "pairs = []\n",
        "for con in conv:\n",
        "    ids = eval(con.split(\" +++$+++ \")[-1])\n",
        "    for i in range(len(ids)):\n",
        "        qa_pairs = []\n",
        "\n",
        "        if i == len(ids) - 1:\n",
        "            break\n",
        "\n",
        "        first = lines_dic[ids[i]].strip()\n",
        "        second = lines_dic[ids[i+1]].strip()\n",
        "\n",
        "        qa_pairs.append(' '.join(first.split()[:MAX_LEN]))\n",
        "        qa_pairs.append(' '.join(second.split()[:MAX_LEN]))\n",
        "        pairs.append(qa_pairs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LiU1O-8C1yEb",
        "outputId": "e8abb30e-ee41-4165-8bc5-156b0abdfe38"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[\"I really, really, really wanna go, but I can't. Not unless my sister goes.\", \"I'm workin' on it. But she doesn't seem to be goin' for him.\"]\n"
          ]
        }
      ],
      "source": [
        "print(pairs[20])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U4TapsN24enc",
        "outputId": "eea0f8d0-b420-447f-d49e-0a1b20f32894"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 221616/221616 [00:00<00:00, 515461.42it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1988: FutureWarning: Calling BertTokenizer.from_pretrained() with the path to a single file or url is deprecated and won't be possible anymore in v5. Use a model identifier or the path to a directory instead.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# WordPiece tokenizer\n",
        "\n",
        "### save data as txt file\n",
        "os.mkdir('./data')\n",
        "text_data = []\n",
        "file_count = 0\n",
        "\n",
        "for sample in tqdm.tqdm([x[0] for x in pairs]):\n",
        "    text_data.append(sample)\n",
        "\n",
        "    # once we hit the 10K mark, save to file\n",
        "    if len(text_data) == 10000:\n",
        "        with open(f'./data/text_{file_count}.txt', 'w', encoding='utf-8') as fp:\n",
        "            fp.write('\\n'.join(text_data))\n",
        "        text_data = []\n",
        "        file_count += 1\n",
        "\n",
        "paths = [str(x) for x in Path('./data').glob('**/*.txt')]\n",
        "\n",
        "### training own tokenizer\n",
        "tokenizer = BertWordPieceTokenizer(\n",
        "    clean_text=True,\n",
        "    handle_chinese_chars=False,\n",
        "    strip_accents=False,\n",
        "    lowercase=True\n",
        ")\n",
        "\n",
        "tokenizer.train(\n",
        "    files=paths,\n",
        "    vocab_size=30_000,\n",
        "    min_frequency=5,\n",
        "    limit_alphabet=1000,\n",
        "    wordpieces_prefix='##',\n",
        "    special_tokens=['[PAD]', '[CLS]', '[SEP]', '[MASK]', '[UNK]']\n",
        "    )\n",
        "\n",
        "os.mkdir('./bert-it-1')\n",
        "tokenizer.save_model('./bert-it-1', 'bert-it')\n",
        "tokenizer = BertTokenizer.from_pretrained('./bert-it-1/bert-it-vocab.txt', local_files_only=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a288Potn4oFO"
      },
      "outputs": [],
      "source": [
        "class BERTDataset(Dataset):\n",
        "    def __init__(self, data_pair, tokenizer, seq_len=64):\n",
        "\n",
        "        self.tokenizer = tokenizer\n",
        "        self.seq_len = seq_len\n",
        "        self.corpus_lines = len(data_pair)\n",
        "        self.lines = data_pair\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.corpus_lines\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "\n",
        "        # Step 1: get random sentence pair, either negative or positive (saved as is_next_label)\n",
        "        t1, t2, is_next_label = self.get_sent(item)\n",
        "\n",
        "        # Step 2: replace random words in sentence with mask / random words\n",
        "        t1_random, t1_label = self.random_word(t1)\n",
        "        t2_random, t2_label = self.random_word(t2)\n",
        "\n",
        "        # Step 3: Adding CLS and SEP tokens to the start and end of sentences\n",
        "         # Adding PAD token for labels\n",
        "        t1 = [self.tokenizer.vocab['[CLS]']] + t1_random + [self.tokenizer.vocab['[SEP]']]\n",
        "        t2 = t2_random + [self.tokenizer.vocab['[SEP]']]\n",
        "        t1_label = [self.tokenizer.vocab['[PAD]']] + t1_label + [self.tokenizer.vocab['[PAD]']]\n",
        "        t2_label = t2_label + [self.tokenizer.vocab['[PAD]']]\n",
        "\n",
        "        # Step 4: combine sentence 1 and 2 as one input\n",
        "        # adding PAD tokens to make the sentence same length as seq_len\n",
        "        segment_label = ([1 for _ in range(len(t1))] + [2 for _ in range(len(t2))])[:self.seq_len]\n",
        "        bert_input = (t1 + t2)[:self.seq_len]\n",
        "        bert_label = (t1_label + t2_label)[:self.seq_len]\n",
        "        padding = [self.tokenizer.vocab['[PAD]'] for _ in range(self.seq_len - len(bert_input))]\n",
        "        bert_input.extend(padding), bert_label.extend(padding), segment_label.extend(padding)\n",
        "\n",
        "        output = {\"bert_input\": bert_input,\n",
        "                  \"bert_label\": bert_label,\n",
        "                  \"segment_label\": segment_label,\n",
        "                  \"is_next\": is_next_label}\n",
        "\n",
        "        return {key: torch.tensor(value) for key, value in output.items()}\n",
        "\n",
        "    def random_word(self, sentence):\n",
        "        tokens = sentence.split()\n",
        "        output_label = []\n",
        "        output = []\n",
        "\n",
        "        # 15% of the tokens would be replaced\n",
        "        for i, token in enumerate(tokens):\n",
        "            prob = random.random()\n",
        "\n",
        "            # remove cls and sep token\n",
        "            token_id = self.tokenizer(token)['input_ids'][1:-1]\n",
        "\n",
        "            if prob < 0.15:\n",
        "                prob /= 0.15\n",
        "\n",
        "                # 80% chance change token to mask token\n",
        "                if prob < 0.8:\n",
        "                    for i in range(len(token_id)):\n",
        "                        output.append(self.tokenizer.vocab['[MASK]'])\n",
        "\n",
        "                # 10% chance change token to random token\n",
        "                elif prob < 0.9:\n",
        "                    for i in range(len(token_id)):\n",
        "                        output.append(random.randrange(len(self.tokenizer.vocab)))\n",
        "\n",
        "                # 10% chance change token to current token\n",
        "                else:\n",
        "                    output.append(token_id)\n",
        "\n",
        "                output_label.append(token_id)\n",
        "\n",
        "            else:\n",
        "                output.append(token_id)\n",
        "                for i in range(len(token_id)):\n",
        "                    output_label.append(0)\n",
        "\n",
        "        # flattening\n",
        "        output = list(itertools.chain(*[[x] if not isinstance(x, list) else x for x in output]))\n",
        "        output_label = list(itertools.chain(*[[x] if not isinstance(x, list) else x for x in output_label]))\n",
        "        assert len(output) == len(output_label)\n",
        "        return output, output_label\n",
        "\n",
        "    def get_sent(self, index):\n",
        "        '''return random sentence pair'''\n",
        "        t1, t2 = self.get_corpus_line(index)\n",
        "\n",
        "        # negative or positive pair, for next sentence prediction\n",
        "        if random.random() > 0.5:\n",
        "            return t1, t2, 1\n",
        "        else:\n",
        "            return t1, self.get_random_line(), 0\n",
        "\n",
        "    def get_corpus_line(self, item):\n",
        "        '''return sentence pair'''\n",
        "        return self.lines[item][0], self.lines[item][1]\n",
        "\n",
        "    def get_random_line(self):\n",
        "        '''return random single sentence'''\n",
        "        return self.lines[random.randrange(len(self.lines))][1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ncUhIMXk4tWo",
        "outputId": "dc3c6eb5-4f7e-4d83-8c90-6569396695d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'bert_input': tensor([   1,  662,   16,   16,   48,  204,   11,   59,  501,  210,  211,  607,\n",
            "          17,    2, 3195,  110,   17, 3037, 3195,  110,   17,    2,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0]), 'bert_label': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'segment_label': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'is_next': tensor(1)}\n"
          ]
        }
      ],
      "source": [
        "train_data = BERTDataset(\n",
        "   pairs, seq_len=MAX_LEN, tokenizer=tokenizer)\n",
        "train_loader = DataLoader(\n",
        "   train_data, batch_size=32, shuffle=True, pin_memory=True)\n",
        "sample_data = next(iter(train_loader))\n",
        "print(train_data[random.randrange(len(train_data))])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xR1DUJJw4w5v"
      },
      "outputs": [],
      "source": [
        "class PositionalEmbedding(torch.nn.Module):\n",
        "\n",
        "    def __init__(self, d_model, max_len=128):\n",
        "        super().__init__()\n",
        "\n",
        "        # Compute the positional encodings once in log space.\n",
        "        pe = torch.zeros(max_len, d_model).float()\n",
        "        pe.require_grad = False\n",
        "\n",
        "        for pos in range(max_len):\n",
        "            # for each dimension of the each position\n",
        "            for i in range(0, d_model, 2):\n",
        "                pe[pos, i] = math.sin(pos / (10000 ** ((2 * i)/d_model)))\n",
        "                pe[pos, i + 1] = math.cos(pos / (10000 ** ((2 * (i + 1))/d_model)))\n",
        "\n",
        "        # include the batch size\n",
        "        self.pe = pe.unsqueeze(0)\n",
        "        # self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.pe\n",
        "\n",
        "class BERTEmbedding(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    BERT Embedding which is consisted with under features\n",
        "        1. TokenEmbedding : normal embedding matrix\n",
        "        2. PositionalEmbedding : adding positional information using sin, cos\n",
        "        2. SegmentEmbedding : adding sentence segment info, (sent_A:1, sent_B:2)\n",
        "        sum of all these features are output of BERTEmbedding\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, vocab_size, embed_size, seq_len=64, dropout=0.1):\n",
        "        \"\"\"\n",
        "        :param vocab_size: total vocab size\n",
        "        :param embed_size: embedding size of token embedding\n",
        "        :param dropout: dropout rate\n",
        "        \"\"\"\n",
        "\n",
        "        super().__init__()\n",
        "        self.embed_size = embed_size\n",
        "        # (m, seq_len) --> (m, seq_len, embed_size)\n",
        "        # padding_idx is not updated during training, remains as fixed pad (0)\n",
        "        self.token = torch.nn.Embedding(vocab_size, embed_size, padding_idx=0)\n",
        "        self.segment = torch.nn.Embedding(3, embed_size, padding_idx=0)\n",
        "        self.position = PositionalEmbedding(d_model=embed_size, max_len=seq_len)\n",
        "        self.dropout = torch.nn.Dropout(p=dropout)\n",
        "\n",
        "    def forward(self, sequence, segment_label):\n",
        "        x = self.token(sequence) + self.position(sequence) + self.segment(segment_label)\n",
        "        return self.dropout(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6BTkAHPv41Ic"
      },
      "outputs": [],
      "source": [
        "class GroupedQueryAttention(torch.nn.Module):\n",
        "\n",
        "    def __init__(self, heads, d_model, dropout=0.1):\n",
        "        super(MultiHeadedAttention, self).__init__()\n",
        "\n",
        "        assert d_model % heads == 0\n",
        "        self.d_k = d_model // heads\n",
        "        self.heads = heads\n",
        "        self.dropout = torch.nn.Dropout(dropout)\n",
        "\n",
        "        self.query = torch.nn.Linear(d_model, d_model)\n",
        "        self.key = torch.nn.Linear(d_model, d_model)\n",
        "        self.value = torch.nn.Linear(d_model, d_model)\n",
        "        self.output_linear = torch.nn.Linear(d_model, d_model)\n",
        "\n",
        "    def forward(self, query, key, value, mask):\n",
        "        \"\"\"\n",
        "        query, key, value of shape: (batch_size, max_len, d_model)\n",
        "        mask of shape: (batch_size, 1, 1, max_words)\n",
        "        \"\"\"\n",
        "        # (batch_size, max_len, d_model)\n",
        "        query = self.query(query)\n",
        "        key = self.key(key)\n",
        "        value = self.value(value)\n",
        "\n",
        "        # (batch_size, max_len, d_model) --> (batch_size, max_len, h, d_k) --> (batch_size, h, max_len, d_k)\n",
        "        query = query.view(query.shape[0], -1, self.heads, self.d_k).permute(0, 2, 1, 3)\n",
        "        key = key.view(key.shape[0], -1, self.heads, self.d_k).permute(0, 2, 1, 3)\n",
        "        value = value.view(value.shape[0], -1, self.heads, self.d_k).permute(0, 2, 1, 3)\n",
        "\n",
        "        # (batch_size, h, max_len, d_k) matmul (batch_size, h, d_k, max_len) --> (batch_size, h, max_len, max_len)\n",
        "        scores = torch.matmul(query, key.permute(0, 1, 3, 2)) / math.sqrt(query.size(-1))\n",
        "\n",
        "        # fill 0 mask with super small number so it wont affect the softmax weight\n",
        "        # (batch_size, h, max_len, max_len)\n",
        "        scores = scores.masked_fill(mask == 0, -1e9)\n",
        "\n",
        "        # (batch_size, h, max_len, max_len)\n",
        "        # softmax to put attention weight for all non-pad tokens\n",
        "        # max_len X max_len matrix of attention\n",
        "        weights = F.softmax(scores, dim=-1)\n",
        "        weights = self.dropout(weights)\n",
        "\n",
        "        # (batch_size, h, max_len, max_len) matmul (batch_size, h, max_len, d_k) --> (batch_size, h, max_len, d_k)\n",
        "        context = torch.matmul(weights, value)\n",
        "\n",
        "        # (batch_size, h, max_len, d_k) --> (batch_size, max_len, h, d_k) --> (batch_size, max_len, d_model)\n",
        "        context = context.permute(0, 2, 1, 3).contiguous().view(context.shape[0], -1, self.heads * self.d_k)\n",
        "\n",
        "        # (batch_size, max_len, d_model)\n",
        "        return self.output_linear(context)\n",
        "\n",
        "class FeedForward(torch.nn.Module):\n",
        "    \"Implements FFN equation.\"\n",
        "\n",
        "    def __init__(self, d_model, middle_dim=2048, dropout=0.1):\n",
        "        super(FeedForward, self).__init__()\n",
        "\n",
        "        self.fc1 = torch.nn.Linear(d_model, middle_dim)\n",
        "        self.fc2 = torch.nn.Linear(middle_dim, d_model)\n",
        "        self.dropout = torch.nn.Dropout(dropout)\n",
        "        self.activation = torch.nn.GELU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.activation(self.fc1(x))\n",
        "        out = self.fc2(self.dropout(out))\n",
        "        return out\n",
        "\n",
        "class EncoderLayer(torch.nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        d_model=768,\n",
        "        heads=12,\n",
        "        feed_forward_hidden=768 * 4,\n",
        "        dropout=0.1\n",
        "        ):\n",
        "        super(EncoderLayer, self).__init__()\n",
        "        self.layernorm = torch.nn.LayerNorm(d_model)\n",
        "        self.self_multihead = MultiHeadedAttention(heads, d_model)\n",
        "        self.feed_forward = FeedForward(d_model, middle_dim=feed_forward_hidden)\n",
        "        self.dropout = torch.nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, embeddings, mask):\n",
        "        # embeddings: (batch_size, max_len, d_model)\n",
        "        # encoder mask: (batch_size, 1, 1, max_len)\n",
        "        # result: (batch_size, max_len, d_model)\n",
        "        interacted = self.dropout(self.self_multihead(embeddings, embeddings, embeddings, mask))\n",
        "        # residual layer\n",
        "        interacted = self.layernorm(interacted + embeddings)\n",
        "        # bottleneck\n",
        "        feed_forward_out = self.dropout(self.feed_forward(interacted))\n",
        "        encoded = self.layernorm(feed_forward_out + interacted)\n",
        "        return encoded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5psej8vm46Dp"
      },
      "outputs": [],
      "source": [
        "class BERT(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    BERT model : Bidirectional Encoder Representations from Transformers.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, vocab_size, d_model=768, n_layers=12, heads=12, dropout=0.1):\n",
        "        \"\"\"\n",
        "        :param vocab_size: vocab_size of total words\n",
        "        :param hidden: BERT model hidden size\n",
        "        :param n_layers: numbers of Transformer blocks(layers)\n",
        "        :param attn_heads: number of attention heads\n",
        "        :param dropout: dropout rate\n",
        "        \"\"\"\n",
        "\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "        self.n_layers = n_layers\n",
        "        self.heads = heads\n",
        "\n",
        "        # paper noted they used 4 * hidden_size for ff_network_hidden_size\n",
        "        self.feed_forward_hidden = d_model * 4\n",
        "\n",
        "        # embedding for BERT, sum of positional, segment, token embeddings\n",
        "        self.embedding = BERTEmbedding(vocab_size=vocab_size, embed_size=d_model)\n",
        "\n",
        "        # multi-layers transformer blocks, deep network\n",
        "        self.encoder_blocks = torch.nn.ModuleList(\n",
        "            [EncoderLayer(d_model, heads, d_model * 4, dropout) for _ in range(n_layers)])\n",
        "\n",
        "    def forward(self, x, segment_info):\n",
        "        # attention masking for padded token\n",
        "        # (batch_size, 1, seq_len, seq_len)\n",
        "        mask = (x > 0).unsqueeze(1).repeat(1, x.size(1), 1).unsqueeze(1)\n",
        "\n",
        "        # embedding the indexed sequence to sequence of vectors\n",
        "        x = self.embedding(x, segment_info)\n",
        "\n",
        "        # running over multiple transformer blocks\n",
        "        for encoder in self.encoder_blocks:\n",
        "            x = encoder.forward(x, mask)\n",
        "        return x\n",
        "\n",
        "class NextSentencePrediction(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    2-class classification model : is_next, is_not_next\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, hidden):\n",
        "        \"\"\"\n",
        "        :param hidden: BERT model output size\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.linear = torch.nn.Linear(hidden, 2)\n",
        "        self.softmax = torch.nn.LogSoftmax(dim=-1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # use only the first token which is the [CLS]\n",
        "        return self.softmax(self.linear(x[:, 0]))\n",
        "\n",
        "class MaskedLanguageModel(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    predicting origin token from masked input sequence\n",
        "    n-class classification problem, n-class = vocab_size\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, hidden, vocab_size):\n",
        "        \"\"\"\n",
        "        :param hidden: output size of BERT model\n",
        "        :param vocab_size: total vocab size\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.linear = torch.nn.Linear(hidden, vocab_size)\n",
        "        self.softmax = torch.nn.LogSoftmax(dim=-1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.softmax(self.linear(x))\n",
        "\n",
        "class BERTLM(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    BERT Language Model\n",
        "    Next Sentence Prediction Model + Masked Language Model\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, bert: BERT, vocab_size):\n",
        "        \"\"\"\n",
        "        :param bert: BERT model which should be trained\n",
        "        :param vocab_size: total vocab size for masked_lm\n",
        "        \"\"\"\n",
        "\n",
        "        super().__init__()\n",
        "        self.bert = bert\n",
        "        self.next_sentence = NextSentencePrediction(self.bert.d_model)\n",
        "        self.mask_lm = MaskedLanguageModel(self.bert.d_model, vocab_size)\n",
        "\n",
        "    def forward(self, x, segment_label):\n",
        "        x = self.bert(x, segment_label)\n",
        "        return self.next_sentence(x), self.mask_lm(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6AW0ApIH4-CR"
      },
      "outputs": [],
      "source": [
        "class ScheduledOptim():\n",
        "    '''A simple wrapper class for learning rate scheduling'''\n",
        "\n",
        "    def __init__(self, optimizer, d_model, n_warmup_steps):\n",
        "        self._optimizer = optimizer\n",
        "        self.n_warmup_steps = n_warmup_steps\n",
        "        self.n_current_steps = 0\n",
        "        self.init_lr = np.power(d_model, -0.5)\n",
        "\n",
        "    def step_and_update_lr(self):\n",
        "        \"Step with the inner optimizer\"\n",
        "        self._update_learning_rate()\n",
        "        self._optimizer.step()\n",
        "\n",
        "    def zero_grad(self):\n",
        "        \"Zero out the gradients by the inner optimizer\"\n",
        "        self._optimizer.zero_grad()\n",
        "\n",
        "    def _get_lr_scale(self):\n",
        "        return np.min([\n",
        "            np.power(self.n_current_steps, -0.5),\n",
        "            np.power(self.n_warmup_steps, -1.5) * self.n_current_steps])\n",
        "\n",
        "    def _update_learning_rate(self):\n",
        "        ''' Learning rate scheduling per step '''\n",
        "\n",
        "        self.n_current_steps += 1\n",
        "        lr = self.init_lr * self._get_lr_scale()\n",
        "\n",
        "        for param_group in self._optimizer.param_groups:\n",
        "            param_group['lr'] = lr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "86v-70w65CZW"
      },
      "outputs": [],
      "source": [
        "class BERTTrainer:\n",
        "    def __init__(\n",
        "        self,\n",
        "        model,\n",
        "        train_dataloader,\n",
        "        test_dataloader=None,\n",
        "        lr= 1e-4,\n",
        "        weight_decay=0.01,\n",
        "        betas=(0.9, 0.999),\n",
        "        warmup_steps=10000,\n",
        "        log_freq=10,\n",
        "        device='cuda'\n",
        "        ):\n",
        "\n",
        "        self.device = device\n",
        "        self.model = model\n",
        "        self.train_data = train_dataloader\n",
        "        self.test_data = test_dataloader\n",
        "\n",
        "        # Setting the Adam optimizer with hyper-param\n",
        "        self.optim = Adam(self.model.parameters(), lr=lr, betas=betas, weight_decay=weight_decay)\n",
        "        self.optim_schedule = ScheduledOptim(\n",
        "            self.optim, self.model.bert.d_model, n_warmup_steps=warmup_steps\n",
        "            )\n",
        "\n",
        "        # Using Negative Log Likelihood Loss function for predicting the masked_token\n",
        "        self.criterion = torch.nn.NLLLoss(ignore_index=0)\n",
        "        self.log_freq = log_freq\n",
        "        print(\"Total Parameters:\", sum([p.nelement() for p in self.model.parameters()]))\n",
        "\n",
        "    def train(self, epoch):\n",
        "        self.iteration(epoch, self.train_data)\n",
        "\n",
        "    def test(self, epoch):\n",
        "        self.iteration(epoch, self.test_data, train=False)\n",
        "\n",
        "    def iteration(self, epoch, data_loader, train=True):\n",
        "\n",
        "        avg_loss = 0.0\n",
        "        total_correct = 0\n",
        "        total_element = 0\n",
        "\n",
        "        mode = \"train\" if train else \"test\"\n",
        "\n",
        "        # progress bar\n",
        "        data_iter = tqdm.tqdm(\n",
        "            enumerate(data_loader),\n",
        "            desc=\"EP_%s:%d\" % (mode, epoch),\n",
        "            total=len(data_loader),\n",
        "            bar_format=\"{l_bar}{r_bar}\"\n",
        "        )\n",
        "\n",
        "        for i, data in data_iter:\n",
        "\n",
        "            # 0. batch_data will be sent into the device(GPU or cpu)\n",
        "            data = {key: value.to(self.device) for key, value in data.items()}\n",
        "\n",
        "            # 1. forward the next_sentence_prediction and masked_lm model\n",
        "            next_sent_output, mask_lm_output = self.model.forward(data[\"bert_input\"], data[\"segment_label\"])\n",
        "\n",
        "            # 2-1. NLL(negative log likelihood) loss of is_next classification result\n",
        "            next_loss = self.criterion(next_sent_output, data[\"is_next\"])\n",
        "\n",
        "            # 2-2. NLLLoss of predicting masked token word\n",
        "            # transpose to (m, vocab_size, seq_len) vs (m, seq_len)\n",
        "            # criterion(mask_lm_output.view(-1, mask_lm_output.size(-1)), data[\"bert_label\"].view(-1))\n",
        "            mask_loss = self.criterion(mask_lm_output.transpose(1, 2), data[\"bert_label\"])\n",
        "\n",
        "            # 2-3. Adding next_loss and mask_loss : 3.4 Pre-training Procedure\n",
        "            loss = next_loss + mask_loss\n",
        "\n",
        "            # 3. backward and optimization only in train\n",
        "            if train:\n",
        "                self.optim_schedule.zero_grad()\n",
        "                loss.backward()\n",
        "                self.optim_schedule.step_and_update_lr()\n",
        "\n",
        "            # next sentence prediction accuracy\n",
        "            correct = next_sent_output.argmax(dim=-1).eq(data[\"is_next\"]).sum().item()\n",
        "            avg_loss += loss.item()\n",
        "            total_correct += correct\n",
        "            total_element += data[\"is_next\"].nelement()\n",
        "\n",
        "            post_fix = {\n",
        "                \"epoch\": epoch,\n",
        "                \"iter\": i,\n",
        "                \"avg_loss\": avg_loss / (i + 1),\n",
        "                \"avg_acc\": total_correct / total_element * 100,\n",
        "                \"loss\": loss.item()\n",
        "            }\n",
        "\n",
        "            if i % self.log_freq == 0:\n",
        "                data_iter.write(str(post_fix))\n",
        "        print(\n",
        "            f\"EP{epoch}, {mode}: \\\n",
        "            avg_loss={avg_loss / len(data_iter)}, \\\n",
        "            total_acc={total_correct * 100.0 / total_element}\"\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "sIXVA6Fk5Hkj",
        "outputId": "d027c5b0-ffec-47f3-e40e-78e001cac112"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total Parameters: 46697897\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:0:   0%|| 1/6926 [00:11<21:34:42, 11.22s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 0, 'iter': 0, 'avg_loss': 10.477503776550293, 'avg_acc': 40.625, 'loss': 10.477503776550293}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:0:   0%|| 11/6926 [01:37<15:25:03,  8.03s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 0, 'iter': 10, 'avg_loss': 10.458698446100408, 'avg_acc': 48.29545454545455, 'loss': 10.43143081665039}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:0:   0%|| 21/6926 [02:56<15:04:23,  7.86s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 0, 'iter': 20, 'avg_loss': 10.4233462924049, 'avg_acc': 47.61904761904761, 'loss': 10.418500900268555}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:0:   0%|| 31/6926 [04:13<14:34:47,  7.61s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 0, 'iter': 30, 'avg_loss': 10.382214884604178, 'avg_acc': 48.79032258064516, 'loss': 10.219169616699219}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:0:   1%|| 41/6926 [05:31<14:36:54,  7.64s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 0, 'iter': 40, 'avg_loss': 10.341149679044397, 'avg_acc': 50.53353658536586, 'loss': 10.17393970489502}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:0:   1%|| 51/6926 [06:50<14:40:25,  7.68s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 0, 'iter': 50, 'avg_loss': 10.290765743629605, 'avg_acc': 50.18382352941176, 'loss': 9.952731132507324}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:0:   1%|| 61/6926 [08:13<17:34:31,  9.22s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 0, 'iter': 60, 'avg_loss': 10.251561977824228, 'avg_acc': 50.204918032786885, 'loss': 9.986059188842773}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:0:   1%|| 71/6926 [09:32<15:35:37,  8.19s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 0, 'iter': 70, 'avg_loss': 10.204131502500722, 'avg_acc': 50.26408450704225, 'loss': 9.781913757324219}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:0:   1%|| 81/6926 [10:51<15:11:24,  7.99s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 0, 'iter': 80, 'avg_loss': 10.160017649332682, 'avg_acc': 50.11574074074075, 'loss': 9.719656944274902}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:0:   1%|| 91/6926 [12:08<15:03:25,  7.93s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 0, 'iter': 90, 'avg_loss': 10.110961494864998, 'avg_acc': 50.54945054945055, 'loss': 9.726557731628418}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:0:   1%|| 101/6926 [13:29<15:01:48,  7.93s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 0, 'iter': 100, 'avg_loss': 10.063525624794535, 'avg_acc': 50.15470297029702, 'loss': 9.467514038085938}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:0:   2%|| 111/6926 [14:46<14:54:56,  7.88s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 0, 'iter': 110, 'avg_loss': 10.014270344296017, 'avg_acc': 50.39414414414415, 'loss': 9.465133666992188}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:0:   2%|| 121/6926 [16:04<14:53:22,  7.88s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 0, 'iter': 120, 'avg_loss': 9.960904799217035, 'avg_acc': 50.25826446280992, 'loss': 9.217521667480469}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:0:   2%|| 131/6926 [17:22<14:52:21,  7.88s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 0, 'iter': 130, 'avg_loss': 9.905557814445205, 'avg_acc': 50.14312977099237, 'loss': 9.108625411987305}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:0:   2%|| 141/6926 [18:38<14:15:28,  7.56s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 0, 'iter': 140, 'avg_loss': 9.848532250586976, 'avg_acc': 49.734042553191486, 'loss': 8.968135833740234}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:0:   2%|| 151/6926 [19:57<15:15:03,  8.10s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 0, 'iter': 150, 'avg_loss': 9.788286720680086, 'avg_acc': 49.48261589403973, 'loss': 8.764547348022461}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:0:   2%|| 161/6926 [21:14<14:21:20,  7.64s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 0, 'iter': 160, 'avg_loss': 9.732072830200195, 'avg_acc': 49.57298136645963, 'loss': 9.003360748291016}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:0:   2%|| 171/6926 [22:31<14:11:24,  7.56s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 0, 'iter': 170, 'avg_loss': 9.668948045250966, 'avg_acc': 49.79897660818713, 'loss': 8.618836402893066}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:0:   3%|| 181/6926 [23:50<14:30:46,  7.75s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 0, 'iter': 180, 'avg_loss': 9.608836869508522, 'avg_acc': 49.896408839779006, 'loss': 8.798079490661621}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:0:   3%|| 191/6926 [25:08<14:11:39,  7.59s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 0, 'iter': 190, 'avg_loss': 9.556382923226082, 'avg_acc': 50.032722513089, 'loss': 8.630485534667969}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:0:   3%|| 201/6926 [26:26<14:17:07,  7.65s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 0, 'iter': 200, 'avg_loss': 9.501377314477418, 'avg_acc': 50.077736318407965, 'loss': 8.651959419250488}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:0:   3%|| 211/6926 [27:45<14:27:59,  7.76s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 0, 'iter': 210, 'avg_loss': 9.448073045902342, 'avg_acc': 49.97037914691943, 'loss': 8.332197189331055}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:0:   3%|| 221/6926 [29:03<14:20:42,  7.70s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 0, 'iter': 220, 'avg_loss': 9.398857043339657, 'avg_acc': 50.32522624434389, 'loss': 8.15330982208252}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:0:   3%|| 231/6926 [30:20<14:12:05,  7.64s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 0, 'iter': 230, 'avg_loss': 9.34546776560994, 'avg_acc': 50.121753246753244, 'loss': 8.260716438293457}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:0:   3%|| 241/6926 [31:39<14:32:10,  7.83s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 0, 'iter': 240, 'avg_loss': 9.295069571847243, 'avg_acc': 50.064834024896264, 'loss': 8.184362411499023}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:0:   4%|| 251/6926 [32:56<14:31:54,  7.84s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 0, 'iter': 250, 'avg_loss': 9.241113691215972, 'avg_acc': 50.04980079681275, 'loss': 7.690189361572266}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:0:   4%|| 261/6926 [34:14<14:27:42,  7.81s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 0, 'iter': 260, 'avg_loss': 9.192039714462455, 'avg_acc': 50.01197318007663, 'loss': 7.873571395874023}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:0:   4%|| 271/6926 [35:33<14:36:44,  7.90s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 0, 'iter': 270, 'avg_loss': 9.142934788637056, 'avg_acc': 49.94234317343174, 'loss': 8.259242057800293}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:0:   4%|| 281/6926 [36:51<14:22:43,  7.79s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 0, 'iter': 280, 'avg_loss': 9.094390597631923, 'avg_acc': 49.96663701067616, 'loss': 7.99195671081543}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:0:   4%|| 291/6926 [38:09<14:28:28,  7.85s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 0, 'iter': 290, 'avg_loss': 9.049156149638067, 'avg_acc': 50.09664948453608, 'loss': 7.907589912414551}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:0:   4%|| 301/6926 [39:28<14:34:19,  7.92s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 0, 'iter': 300, 'avg_loss': 9.003774826708822, 'avg_acc': 50.10382059800664, 'loss': 8.146318435668945}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:0:   4%|| 311/6926 [40:45<14:21:04,  7.81s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 0, 'iter': 310, 'avg_loss': 8.959640535127695, 'avg_acc': 50.10048231511254, 'loss': 7.464275360107422}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:0:   5%|| 321/6926 [42:02<14:11:52,  7.74s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 0, 'iter': 320, 'avg_loss': 8.917443856272, 'avg_acc': 50.13629283489096, 'loss': 7.587379455566406}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:0:   5%|| 331/6926 [43:21<14:22:07,  7.84s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 0, 'iter': 330, 'avg_loss': 8.877878807102446, 'avg_acc': 50.17938066465257, 'loss': 7.928618907928467}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:0:   5%|| 341/6926 [44:37<13:48:59,  7.55s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 0, 'iter': 340, 'avg_loss': 8.835726511443465, 'avg_acc': 50.219941348973606, 'loss': 7.498889446258545}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:0:   5%|| 351/6926 [45:56<14:42:09,  8.05s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 0, 'iter': 350, 'avg_loss': 8.797205040597508, 'avg_acc': 50.15135327635327, 'loss': 6.991869926452637}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:0:   5%|| 361/6926 [47:13<13:50:05,  7.59s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 0, 'iter': 360, 'avg_loss': 8.762224600255655, 'avg_acc': 50.0952216066482, 'loss': 7.425559043884277}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:0:   5%|| 371/6926 [48:31<14:04:12,  7.73s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 0, 'iter': 370, 'avg_loss': 8.726695376907719, 'avg_acc': 50.14319407008087, 'loss': 7.316982746124268}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:0:   6%|| 381/6926 [49:51<14:26:01,  7.94s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 0, 'iter': 380, 'avg_loss': 8.688792776873731, 'avg_acc': 50.123031496063, 'loss': 7.283578395843506}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:0:   6%|| 391/6926 [51:08<13:53:44,  7.65s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 0, 'iter': 390, 'avg_loss': 8.652679542141497, 'avg_acc': 50.0, 'loss': 7.612420558929443}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:0:   6%|| 401/6926 [52:26<13:51:18,  7.64s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 0, 'iter': 400, 'avg_loss': 8.61871612101719, 'avg_acc': 49.984413965087285, 'loss': 7.224196434020996}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:0:   6%|| 411/6926 [53:45<14:21:20,  7.93s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 0, 'iter': 410, 'avg_loss': 8.581930157041898, 'avg_acc': 49.969586374695865, 'loss': 6.739001274108887}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:0:   6%|| 421/6926 [55:02<13:56:09,  7.71s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 0, 'iter': 420, 'avg_loss': 8.546316627085634, 'avg_acc': 50.05195961995249, 'loss': 7.151700973510742}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:0:   6%|| 431/6926 [56:20<14:06:31,  7.82s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 0, 'iter': 430, 'avg_loss': 8.513854644138133, 'avg_acc': 50.06525522041764, 'loss': 6.89253568649292}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:0:   6%|| 441/6926 [57:39<14:21:38,  7.97s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 0, 'iter': 440, 'avg_loss': 8.479788916451591, 'avg_acc': 50.021258503401356, 'loss': 6.835865020751953}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:0:   7%|| 451/6926 [58:56<13:59:47,  7.78s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 0, 'iter': 450, 'avg_loss': 8.44746359806103, 'avg_acc': 50.090077605321504, 'loss': 6.9905104637146}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:0:   7%|| 461/6926 [1:00:14<13:56:41,  7.77s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 0, 'iter': 460, 'avg_loss': 8.413474079843716, 'avg_acc': 50.03389370932755, 'loss': 6.817453861236572}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:0:   7%|| 471/6926 [1:01:32<14:28:40,  8.07s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 0, 'iter': 470, 'avg_loss': 8.384384387111462, 'avg_acc': 50.06634819532909, 'loss': 6.988796234130859}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:0:   7%|| 481/6926 [1:02:51<14:08:07,  7.90s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 0, 'iter': 480, 'avg_loss': 8.352839934850682, 'avg_acc': 50.097453222453225, 'loss': 6.652106761932373}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:0:   7%|| 491/6926 [1:04:09<13:58:54,  7.82s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 0, 'iter': 490, 'avg_loss': 8.32270823573872, 'avg_acc': 49.99363543788187, 'loss': 6.834131240844727}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:0:   7%|| 501/6926 [1:05:27<14:23:54,  8.07s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 0, 'iter': 500, 'avg_loss': 8.293313275792165, 'avg_acc': 50.031187624750494, 'loss': 7.085626125335693}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:0:   7%|| 511/6926 [1:06:45<13:49:50,  7.76s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 0, 'iter': 510, 'avg_loss': 8.264312090005893, 'avg_acc': 50.0366927592955, 'loss': 7.332941055297852}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:0:   8%|| 521/6926 [1:08:02<13:50:37,  7.78s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 0, 'iter': 520, 'avg_loss': 8.232254366957067, 'avg_acc': 50.0059980806142, 'loss': 6.881377220153809}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:0:   8%|| 531/6926 [1:09:21<14:27:55,  8.14s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 0, 'iter': 530, 'avg_loss': 8.204876742569516, 'avg_acc': 49.95880414312618, 'loss': 6.678467273712158}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:0:   8%|| 541/6926 [1:10:40<14:03:32,  7.93s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 0, 'iter': 540, 'avg_loss': 8.179300549731016, 'avg_acc': 49.97689463955638, 'loss': 6.9767165184021}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:0:   8%|| 551/6926 [1:11:58<13:59:20,  7.90s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 0, 'iter': 550, 'avg_loss': 8.153657155114812, 'avg_acc': 50.05104355716878, 'loss': 6.430020332336426}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:0:   8%|| 561/6926 [1:13:17<14:23:41,  8.14s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 0, 'iter': 560, 'avg_loss': 8.127286751215046, 'avg_acc': 50.02785204991087, 'loss': 6.31472635269165}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:0:   8%|| 571/6926 [1:14:35<13:58:33,  7.92s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 0, 'iter': 570, 'avg_loss': 8.103668140237678, 'avg_acc': 50.021891418563925, 'loss': 6.904369354248047}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:0:   8%|| 581/6926 [1:15:52<13:59:03,  7.93s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 0, 'iter': 580, 'avg_loss': 8.07909875154085, 'avg_acc': 50.026893287435456, 'loss': 6.091641426086426}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:0:   9%|| 591/6926 [1:17:11<14:33:23,  8.27s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 0, 'iter': 590, 'avg_loss': 8.053990271289134, 'avg_acc': 50.05816412859561, 'loss': 6.893572807312012}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:0:   9%|| 601/6926 [1:18:29<13:51:18,  7.89s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 0, 'iter': 600, 'avg_loss': 8.028670995683717, 'avg_acc': 50.098793677204654, 'loss': 6.696671962738037}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:0:   9%|| 611/6926 [1:19:47<14:01:15,  7.99s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 0, 'iter': 610, 'avg_loss': 8.005701228171441, 'avg_acc': 50.08183306055647, 'loss': 6.367549419403076}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:0:   9%|| 621/6926 [1:21:06<14:30:27,  8.28s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 0, 'iter': 620, 'avg_loss': 7.98087724049886, 'avg_acc': 50.07045088566827, 'loss': 6.575814247131348}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:0:   9%|| 631/6926 [1:22:23<13:38:15,  7.80s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 0, 'iter': 630, 'avg_loss': 7.956858988609254, 'avg_acc': 50.084191759112514, 'loss': 6.332982063293457}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:0:   9%|| 641/6926 [1:23:40<13:12:45,  7.57s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 0, 'iter': 640, 'avg_loss': 7.930675486506613, 'avg_acc': 50.102379095163805, 'loss': 6.429091453552246}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:0:   9%|| 651/6926 [1:24:58<13:15:01,  7.60s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 0, 'iter': 650, 'avg_loss': 7.907327635130757, 'avg_acc': 50.134408602150536, 'loss': 7.121767520904541}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:0:  10%|| 661/6926 [1:26:17<13:20:42,  7.67s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 0, 'iter': 660, 'avg_loss': 7.884923120490001, 'avg_acc': 50.15128593040848, 'loss': 6.380463123321533}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:0:  10%|| 671/6926 [1:27:34<13:09:37,  7.57s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 0, 'iter': 670, 'avg_loss': 7.862733258220372, 'avg_acc': 50.17231743666169, 'loss': 6.256093502044678}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:0:  10%|| 681/6926 [1:28:52<13:18:36,  7.67s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 0, 'iter': 680, 'avg_loss': 7.842743066964171, 'avg_acc': 50.21108663729809, 'loss': 6.363301753997803}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:0:  10%|| 691/6926 [1:30:11<13:21:50,  7.72s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 0, 'iter': 690, 'avg_loss': 7.82163205333108, 'avg_acc': 50.16732995658466, 'loss': 6.217895984649658}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:0:  10%|| 701/6926 [1:31:29<13:11:58,  7.63s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 0, 'iter': 700, 'avg_loss': 7.800645186795657, 'avg_acc': 50.160485021398, 'loss': 6.561810493469238}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:0:  10%|| 711/6926 [1:32:47<13:15:11,  7.68s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 0, 'iter': 710, 'avg_loss': 7.779201942154124, 'avg_acc': 50.17141350210971, 'loss': 6.41469669342041}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:0:  10%|| 721/6926 [1:34:05<13:20:08,  7.74s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 0, 'iter': 720, 'avg_loss': 7.7612576206910955, 'avg_acc': 50.20804438280167, 'loss': 6.529196739196777}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:0:  11%|| 731/6926 [1:35:24<13:19:25,  7.74s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 0, 'iter': 730, 'avg_loss': 7.740066035827762, 'avg_acc': 50.222298221614224, 'loss': 6.076756000518799}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:0:  11%|| 741/6926 [1:36:41<13:17:58,  7.74s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 0, 'iter': 740, 'avg_loss': 7.72010056692579, 'avg_acc': 50.189777327935225, 'loss': 6.568907260894775}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:0:  11%|| 751/6926 [1:38:00<13:15:27,  7.73s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 0, 'iter': 750, 'avg_loss': 7.699147035215254, 'avg_acc': 50.12899467376831, 'loss': 6.025121688842773}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:0:  11%|| 761/6926 [1:39:18<13:17:22,  7.76s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 0, 'iter': 760, 'avg_loss': 7.679779451247427, 'avg_acc': 50.16425755584757, 'loss': 6.450368881225586}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:0:  11%|| 771/6926 [1:40:35<13:15:28,  7.75s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 0, 'iter': 770, 'avg_loss': 7.661667915324448, 'avg_acc': 50.14996757457847, 'loss': 6.0526299476623535}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:0:  11%|| 781/6926 [1:41:55<13:30:09,  7.91s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 0, 'iter': 780, 'avg_loss': 7.643658176427004, 'avg_acc': 50.148047375160054, 'loss': 6.086098670959473}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:0:  11%|| 791/6926 [1:43:12<13:18:46,  7.81s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 0, 'iter': 790, 'avg_loss': 7.626164647330225, 'avg_acc': 50.15012642225032, 'loss': 6.693759441375732}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:0:  12%|| 801/6926 [1:44:30<13:16:00,  7.80s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 0, 'iter': 800, 'avg_loss': 7.609624790044015, 'avg_acc': 50.15215355805244, 'loss': 6.302680492401123}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:0:  12%|| 811/6926 [1:45:49<13:28:51,  7.94s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 0, 'iter': 810, 'avg_loss': 7.593006469759488, 'avg_acc': 50.1772503082614, 'loss': 6.511666774749756}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:0:  12%|| 821/6926 [1:47:07<13:19:51,  7.86s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 0, 'iter': 820, 'avg_loss': 7.5753292305606, 'avg_acc': 50.15605968331304, 'loss': 6.0558390617370605}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:0:  12%|| 831/6926 [1:48:24<13:20:12,  7.88s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 0, 'iter': 830, 'avg_loss': 7.55848187860886, 'avg_acc': 50.13161853188929, 'loss': 6.198967456817627}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:0:  12%|| 841/6926 [1:49:44<13:25:05,  7.94s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 0, 'iter': 840, 'avg_loss': 7.5420314457697195, 'avg_acc': 50.126337693222354, 'loss': 6.3086748123168945}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:0:  12%|| 851/6926 [1:51:02<13:20:10,  7.90s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 0, 'iter': 850, 'avg_loss': 7.52577580016032, 'avg_acc': 50.157902467685076, 'loss': 6.169374465942383}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:0:  12%|| 861/6926 [1:52:19<13:14:24,  7.86s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 0, 'iter': 860, 'avg_loss': 7.509777883757836, 'avg_acc': 50.177845528455286, 'loss': 6.588799953460693}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:0:  13%|| 871/6926 [1:53:37<13:44:46,  8.17s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 0, 'iter': 870, 'avg_loss': 7.494147043961745, 'avg_acc': 50.11839839265212, 'loss': 5.804925918579102}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:0:  13%|| 881/6926 [1:54:55<13:09:06,  7.83s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 0, 'iter': 880, 'avg_loss': 7.479350276215258, 'avg_acc': 50.12769580022701, 'loss': 6.077070236206055}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:0:  13%|| 891/6926 [1:56:12<12:53:08,  7.69s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 0, 'iter': 890, 'avg_loss': 7.464449918898937, 'avg_acc': 50.11223344556678, 'loss': 5.848381996154785}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:0:  13%|| 901/6926 [1:57:31<13:10:34,  7.87s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 0, 'iter': 900, 'avg_loss': 7.448957116701759, 'avg_acc': 50.08324084350721, 'loss': 6.231287002563477}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:0:  13%|| 911/6926 [1:58:49<12:45:58,  7.64s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 0, 'iter': 910, 'avg_loss': 7.435378597544263, 'avg_acc': 50.12692096597146, 'loss': 6.456010341644287}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:0:  13%|| 921/6926 [2:00:07<12:48:24,  7.68s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 0, 'iter': 920, 'avg_loss': 7.421711977089914, 'avg_acc': 50.09161237785016, 'loss': 6.177309513092041}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:0:  13%|| 931/6926 [2:01:25<12:41:47,  7.62s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 0, 'iter': 930, 'avg_loss': 7.406731400658826, 'avg_acc': 50.10069817400644, 'loss': 5.848144054412842}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:0:  14%|| 941/6926 [2:02:44<12:45:41,  7.68s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 0, 'iter': 940, 'avg_loss': 7.391375850288318, 'avg_acc': 50.07638150903294, 'loss': 6.409902572631836}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:0:  14%|| 951/6926 [2:04:02<12:50:19,  7.74s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 0, 'iter': 950, 'avg_loss': 7.37832071001472, 'avg_acc': 50.09858044164039, 'loss': 6.233436584472656}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:0:  14%|| 961/6926 [2:05:19<12:37:08,  7.62s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 0, 'iter': 960, 'avg_loss': 7.366254203153327, 'avg_acc': 50.11381373569199, 'loss': 6.137256622314453}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:0:  14%|| 971/6926 [2:06:36<12:36:44,  7.62s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 0, 'iter': 970, 'avg_loss': 7.353000834845122, 'avg_acc': 50.0933316168898, 'loss': 5.821027755737305}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:0:  14%|| 981/6926 [2:07:53<12:30:30,  7.57s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 0, 'iter': 980, 'avg_loss': 7.34041686986443, 'avg_acc': 50.05096839959226, 'loss': 6.124034881591797}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:0:  14%|| 991/6926 [2:09:11<12:38:35,  7.67s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 0, 'iter': 990, 'avg_loss': 7.326815250061836, 'avg_acc': 50.100908173562054, 'loss': 5.860959053039551}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:0:  14%|| 1001/6926 [2:10:29<12:37:37,  7.67s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 0, 'iter': 1000, 'avg_loss': 7.315651861699549, 'avg_acc': 50.109265734265726, 'loss': 6.288549900054932}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:0:  15%|| 1011/6926 [2:11:47<12:57:12,  7.88s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 0, 'iter': 1010, 'avg_loss': 7.303286470833919, 'avg_acc': 50.09891196834817, 'loss': 6.262579917907715}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:0:  15%|| 1021/6926 [2:13:04<12:54:28,  7.87s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 0, 'iter': 1020, 'avg_loss': 7.290152812214252, 'avg_acc': 50.06121449559255, 'loss': 6.055438041687012}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:0:  15%|| 1031/6926 [2:14:23<13:09:06,  8.03s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 0, 'iter': 1030, 'avg_loss': 7.277964764954857, 'avg_acc': 50.112148399612025, 'loss': 5.761253833770752}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:0:  15%|| 1041/6926 [2:15:47<12:46:42,  7.82s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 0, 'iter': 1040, 'avg_loss': 7.266252904758216, 'avg_acc': 50.138088376560994, 'loss': 6.381381511688232}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:0:  15%|| 1051/6926 [2:17:04<12:26:55,  7.63s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 0, 'iter': 1050, 'avg_loss': 7.2538083545601335, 'avg_acc': 50.14272121788773, 'loss': 5.879632949829102}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:0:  15%|| 1061/6926 [2:18:22<12:55:57,  7.94s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 0, 'iter': 1060, 'avg_loss': 7.2416315015816215, 'avg_acc': 50.15021206409048, 'loss': 5.669497966766357}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:0:  15%|| 1071/6926 [2:19:40<12:23:56,  7.62s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 0, 'iter': 1070, 'avg_loss': 7.229646191654864, 'avg_acc': 50.16631652661064, 'loss': 6.020119667053223}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:0:  16%|| 1081/6926 [2:20:57<12:25:08,  7.65s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 0, 'iter': 1080, 'avg_loss': 7.21943106108744, 'avg_acc': 50.11563367252544, 'loss': 6.079394817352295}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:0:  16%|| 1091/6926 [2:22:14<12:15:17,  7.56s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 0, 'iter': 1090, 'avg_loss': 7.207967039644991, 'avg_acc': 50.15753895508708, 'loss': 5.558618068695068}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:0:  16%|| 1101/6926 [2:23:33<12:27:38,  7.70s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 0, 'iter': 1100, 'avg_loss': 7.198262243244888, 'avg_acc': 50.150431425976386, 'loss': 6.368535995483398}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:0:  16%|| 1111/6926 [2:24:51<12:50:32,  7.95s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 0, 'iter': 1110, 'avg_loss': 7.186892286278341, 'avg_acc': 50.157515751575154, 'loss': 5.916105270385742}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:0:  16%|| 1121/6926 [2:26:09<12:43:27,  7.89s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 0, 'iter': 1120, 'avg_loss': 7.1778128608649165, 'avg_acc': 50.17562444246209, 'loss': 5.826920986175537}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:0:  16%|| 1131/6926 [2:27:27<12:32:57,  7.80s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 0, 'iter': 1130, 'avg_loss': 7.167635320668511, 'avg_acc': 50.154730327144115, 'loss': 6.3243088722229}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:0:  16%|| 1141/6926 [2:28:44<12:29:58,  7.78s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 0, 'iter': 1140, 'avg_loss': 7.157138119028076, 'avg_acc': 50.145157756354074, 'loss': 5.844418048858643}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:0:  17%|| 1151/6926 [2:30:01<12:23:06,  7.72s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 0, 'iter': 1150, 'avg_loss': 7.147721793939506, 'avg_acc': 50.1601867940921, 'loss': 6.003031253814697}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:0:  17%|| 1161/6926 [2:31:19<12:35:34,  7.86s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 0, 'iter': 1160, 'avg_loss': 7.137246014433211, 'avg_acc': 50.17764857881137, 'loss': 6.358545303344727}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:0:  17%|| 1171/6926 [2:32:36<12:29:43,  7.82s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 0, 'iter': 1170, 'avg_loss': 7.1284087443331385, 'avg_acc': 50.1948121263877, 'loss': 5.659242153167725}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:0:  17%|| 1181/6926 [2:33:53<12:25:03,  7.78s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 0, 'iter': 1180, 'avg_loss': 7.11783124066126, 'avg_acc': 50.2037468247248, 'loss': 5.785782337188721}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:0:  17%|| 1191/6926 [2:35:11<12:35:17,  7.90s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 0, 'iter': 1190, 'avg_loss': 7.107240689291261, 'avg_acc': 50.20203610411419, 'loss': 5.640407562255859}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:0:  17%|| 1201/6926 [2:36:28<12:11:36,  7.67s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 0, 'iter': 1200, 'avg_loss': 7.09660206547784, 'avg_acc': 50.187343880099924, 'loss': 5.5756635665893555}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:0:  17%|| 1211/6926 [2:37:45<12:09:58,  7.66s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 0, 'iter': 1210, 'avg_loss': 7.087825649538678, 'avg_acc': 50.15999174236169, 'loss': 5.955317497253418}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:0:  18%|| 1221/6926 [2:39:02<12:12:28,  7.70s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 0, 'iter': 1220, 'avg_loss': 7.078778659779942, 'avg_acc': 50.13052825552825, 'loss': 5.7555975914001465}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:0:  18%|| 1231/6926 [2:40:21<12:20:14,  7.80s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 0, 'iter': 1230, 'avg_loss': 7.069952725783099, 'avg_acc': 50.13708367181153, 'loss': 5.382364273071289}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:0:  18%|| 1241/6926 [2:41:39<12:02:26,  7.62s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 0, 'iter': 1240, 'avg_loss': 7.0600550484023294, 'avg_acc': 50.108279613215146, 'loss': 5.735016345977783}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:0:  18%|| 1251/6926 [2:42:55<11:50:52,  7.52s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 0, 'iter': 1250, 'avg_loss': 7.0506150396607765, 'avg_acc': 50.11241007194245, 'loss': 6.401092052459717}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:0:  18%|| 1261/6926 [2:44:14<12:01:51,  7.65s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 0, 'iter': 1260, 'avg_loss': 7.043451981918856, 'avg_acc': 50.10408406026963, 'loss': 5.806425094604492}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:0:  18%|| 1271/6926 [2:45:32<12:21:33,  7.87s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 0, 'iter': 1270, 'avg_loss': 7.035122225736653, 'avg_acc': 50.1008064516129, 'loss': 6.03903865814209}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:0:  18%|| 1281/6926 [2:46:50<12:24:48,  7.92s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 0, 'iter': 1280, 'avg_loss': 7.026268772181824, 'avg_acc': 50.10001951600312, 'loss': 5.594573497772217}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:0:  19%|| 1291/6926 [2:48:08<12:20:30,  7.88s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 0, 'iter': 1290, 'avg_loss': 7.0180457268086265, 'avg_acc': 50.1186096049574, 'loss': 6.078426361083984}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:0:  19%|| 1301/6926 [2:49:25<12:09:55,  7.79s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 0, 'iter': 1300, 'avg_loss': 7.009938496612385, 'avg_acc': 50.10568793235972, 'loss': 5.521821022033691}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:0:  19%|| 1311/6926 [2:50:42<12:11:57,  7.82s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 0, 'iter': 1310, 'avg_loss': 7.001176726808992, 'avg_acc': 50.11203279938978, 'loss': 5.797840595245361}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:0:  19%|| 1321/6926 [2:52:01<12:26:10,  7.99s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 0, 'iter': 1320, 'avg_loss': 6.9921447405934245, 'avg_acc': 50.14193792581377, 'loss': 6.475080966949463}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:0:  19%|| 1331/6926 [2:53:18<12:00:52,  7.73s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 0, 'iter': 1330, 'avg_loss': 6.984209177818269, 'avg_acc': 50.11269722013524, 'loss': 6.312065124511719}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:0:  19%|| 1341/6926 [2:54:35<12:00:36,  7.74s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 0, 'iter': 1340, 'avg_loss': 6.977209968410438, 'avg_acc': 50.10486577181208, 'loss': 6.292248725891113}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:0:  20%|| 1351/6926 [2:55:53<12:18:54,  7.95s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 0, 'iter': 1350, 'avg_loss': 6.969015543236722, 'avg_acc': 50.11796817172465, 'loss': 6.002690315246582}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:0:  20%|| 1361/6926 [2:57:10<11:45:40,  7.61s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 0, 'iter': 1360, 'avg_loss': 6.961085696504188, 'avg_acc': 50.08495591476855, 'loss': 5.4774675369262695}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:0:  20%|| 1371/6926 [2:58:27<11:49:45,  7.67s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 0, 'iter': 1370, 'avg_loss': 6.953276442229357, 'avg_acc': 50.06154266958425, 'loss': 5.8312296867370605}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:0:  20%|| 1381/6926 [2:59:44<11:42:23,  7.60s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 0, 'iter': 1380, 'avg_loss': 6.945630658458403, 'avg_acc': 50.06109703113686, 'loss': 5.508723258972168}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEP_train:0:  20%|| 1382/6926 [2:59:52<11:52:46,  7.71s/it]"
          ]
        }
      ],
      "source": [
        "'''test run'''\n",
        "\n",
        "train_data = BERTDataset(\n",
        "   pairs, seq_len=MAX_LEN, tokenizer=tokenizer)\n",
        "\n",
        "train_loader = DataLoader(\n",
        "   train_data, batch_size=32, shuffle=True, pin_memory=True)\n",
        "\n",
        "bert_model = BERT(\n",
        "  vocab_size=len(tokenizer.vocab),\n",
        "  d_model=768,\n",
        "  n_layers=2,\n",
        "  heads=12,\n",
        "  dropout=0.1\n",
        ")\n",
        "\n",
        "bert_lm = BERTLM(bert_model, len(tokenizer.vocab))\n",
        "bert_trainer = BERTTrainer(bert_lm, train_loader, device='cpu')\n",
        "epochs = 20\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  bert_trainer.train(epoch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WMnC-F_O5MPH"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}